{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\nimport os\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport imageio\n\ntrain_dataset_path = Path(\"/input/traindataset\")  # Update the path to the \"train\" folder\ntest_dataset_path = Path(\"/input/testdataset\")    # Update the path to the \"test\" folder\n\n# Load train images\ntrain_images = list(train_dataset_path.glob(r'**/*.jpg'))\ntrain_labels = [x.parents[0].stem for x in train_images]\n\n# Load test images\ntest_images = list(test_dataset_path.glob(r'**/*.jpg'))\ntest_labels = [x.parents[0].stem for x in test_images]\n\n# Check if there are images in both train and test folders\nif len(train_images) == 0 or len(test_images) == 0:\n    raise ValueError(\"No images found in either the 'train' or 'test' folder.\")\n\n# Convert to pandas Series\ntrain_images = pd.Series(train_images, name=\"mptraintest\").astype(str)\ntrain_labels = pd.Series(train_labels, name=\"Labels\").astype(str)\n\ntest_images = pd.Series(test_images, name=\"mptraintest\").astype(str)\ntest_labels = pd.Series(test_labels, name=\"Labels\").astype(str)\n\n# Create DataFrames\ntrain_data = pd.concat([train_images, train_labels], axis=1)\ntest_data = pd.concat([test_images, test_labels], axis=1)\n\ntrain_data = train_data.sample(frac=1, random_state=42).reset_index(drop=True)\ntest_data = test_data.sample(frac=1, random_state=42).reset_index(drop=True)\n\ntrain_data.head(10)\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import mobilenet\n\ntrain_generator_mobile_net = ImageDataGenerator(\n    preprocessing_function=mobilenet.preprocess_input,\n    validation_split=0.05  # Use 5% of the train data for validation\n)\n\n# Use the entire train data for training and validation\ntrain = train_generator_mobile_net.flow_from_dataframe(\n    dataframe=train_data,\n    x_col=\"mptraintest\",\n    y_col=\"Labels\",\n    target_size=(256, 256),\n    color_mode=\"rgb\",\n    class_mode=\"categorical\",\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='training'  # Use 95% of the train data for training\n)\n\nvalidation = train_generator_mobile_net.flow_from_dataframe(\n    dataframe=train_data,\n    x_col=\"mptraintest\",\n    y_col=\"Labels\",\n    target_size=(256, 256),\n    color_mode=\"rgb\",\n    class_mode=\"categorical\",\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='validation'  # Use 5% of the train data for validation\n)\n\n# Keep the test data for evaluation purposes\ntest_generator_mobile_net = ImageDataGenerator(\n    preprocessing_function=mobilenet.preprocess_input\n)\n\ntest = test_generator_mobile_net.flow_from_dataframe(\n    dataframe=test_data,\n    x_col=\"mptraintest\",\n    y_col=\"Labels\",\n    target_size=(256, 256),\n    color_mode=\"rgb\",\n    class_mode=\"categorical\",\n    batch_size=32,\n    rotation_range=32,\n    zoom_range=0.2,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shuffle=False\n)\n\n\n\nfrom tensorflow.keras.applications import VGG19   # Upadate DCNN model e.g. VGG16, VGG19, ResNet50\n\nVGG_ = VGG19(\n    input_shape=(256, 256, 3),\n    include_top=False,\n    weights=\"imagenet\",\n    pooling='avg'\n)\n\nVGG_.trainable = False\n\n\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.metrics import CategoricalAccuracy\n\n# building the Predictor layers\nx = Dense(256, activation='relu')(VGG_.output)\nx = Dense(128, activation='relu')(x)\nx = Dropout(0.4)(x)\n\noutputs = Dense(30, activation='softmax')(x)\n\nVGG = Model(inputs=VGG_.inputs, outputs=outputs)\n\nVGG.compile(\n    optimizer=Adam(),\n    loss=CategoricalCrossentropy(),\n    metrics=[CategoricalAccuracy()]\n)\n\n\nCHECKPOINTS = Path(\"./checkpoints\")\nCHECKPOINTS.mkdir(exist_ok=True)\n\n\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\n# training\nresults = VGG.fit(\n    train,\n    validation_data = validation,\n    batch_size = 32,\n    epochs = 30,\n    callbacks = [\n        EarlyStopping(\n            monitor=\"val_loss\",\n            patience=4,\n            restore_best_weights=True\n        ), \n        ReduceLROnPlateau(patience=2),\n        ModelCheckpoint(\n            str(CHECKPOINTS),\n            monitor=\"val_loss\",\n            save_best_only=True\n        ),\n    ]\n)\n\n\npd.DataFrame(results.history)[['categorical_accuracy', 'val_categorical_accuracy']].plot()\nplt.title(\"Accuracy\")\nplt.show()\n\n\npd.DataFrame(results.history)[['loss', 'val_loss']].plot()\nplt.title(\"Loss\")\nplt.show()\n\n\ndf=pd.DataFrame(results.history)[['loss', 'val_loss','categorical_accuracy', 'val_categorical_accuracy']]\ndf.to_csv('VGG19.csv',index=False)\n\n\nMODEL_PATH = Path(\"./saved_model\")\nMODEL_PATH.mkdir(exist_ok=True)\nVGG.save(str(MODEL_PATH))\n\n\n# dump the training history as well\nnp.save('model_history.npy', results.history)\n\n# history=np.load('model_history.npy',allow_pickle='TRUE').item()\n\n\n# Testing the model\nresults = VGG.evaluate(test)\n\n\npredictions = np.argmax(VGG.predict(test), axis=1)\n\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\n\npredictions = VGG.predict(test)\nlabels = dict((v, k) for k, v in train.class_indices.items())\npredicted_labels = [labels[i] for i in np.argmax(predictions, axis=1)]\nactual_labels = test_data[\"Labels\"].tolist()\n\n# Compute the classification report\nprint(classification_report(actual_labels, predicted_labels))\n\n# Compute and plot the confusion matrix\ncf = confusion_matrix(actual_labels, predicted_labels, normalize=\"true\")\nplt.figure(figsize=(16, 8))\nsns.heatmap(cf, annot=True, xticklabels=sorted(set(actual_labels)), yticklabels=sorted(set(actual_labels)), cmap='Blues')\nplt.title('VGG19')\nplt.savefig('VGG19.png', bbox_inches='tight', dpi=500)\nplt.show()\n\n\n\nVGG.save('VGG19.h5')\n\n\n","metadata":{"_uuid":"37c36c50-ee0e-40f9-bd2f-6c80f9d54e7e","_cell_guid":"3e1706e6-33b1-41bb-8582-021124196d8d","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}